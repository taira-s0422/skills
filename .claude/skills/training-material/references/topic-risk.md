# リスク管理・セキュリティ・ガバナンス

## 目的

安全に生成AIを活用するための知識を習得する

## 経営層向け重点

- 法的リスクと対策
- 情報漏洩リスク
- ガバナンス体制の構築
- 社内ルール策定

## 管理職向け重点

- 部門でのルール運用
- リスク判断基準
- インシデント対応
- 部下への教育

## 主要リスク領域

### 1. 情報漏洩リスク

| リスク | 内容 | 対策 |
|-------|-----|-----|
| 機密情報の入力 | 企業秘密がAI学習データに | 入力禁止ルールの徹底 |
| 個人情報の入力 | プライバシー侵害 | 匿名化してから入力 |
| 出力の外部共有 | 意図しない情報開示 | 共有前のチェック |

**入力してはいけない情報**
- 顧客の個人情報
- 財務情報（未公開）
- 製品の機密情報
- パスワード・認証情報
- 契約書の詳細

### 2. 著作権・知的財産リスク

| リスク | 内容 | 対策 |
|-------|-----|-----|
| 著作権侵害 | 既存著作物の無断利用 | 出力の確認、引用明記 |
| 商標侵害 | ブランド名の不正使用 | 商標チェック |
| 特許侵害 | 特許技術の無断利用 | 技術内容の確認 |

### 3. ハルシネーション（誤情報）

| リスク | 内容 | 対策 |
|-------|-----|-----|
| 事実と異なる情報 | 存在しない事実の生成 | ファクトチェック必須 |
| 古い情報 | 学習データの時点が古い | 最新情報の確認 |
| 誤った引用 | 存在しない文献の引用 | 出典の検証 |

### 4. バイアスと公平性

| リスク | 内容 | 対策 |
|-------|-----|-----|
| 性別バイアス | 特定性別への偏り | 出力の確認 |
| 人種バイアス | 特定人種への偏り | 多様性チェック |
| 文化バイアス | 特定文化への偏り | 複数視点で確認 |

## 安全な利用ガイドライン

### 入力時のルール

```
1. 機密情報・個人情報は入力しない
2. 必要最小限の情報で依頼
3. 実名・固有名詞は仮名に置換
4. 社外秘文書はそのまま貼り付けない
```

### 出力時のルール

```
1. 事実関係は必ず検証
2. 数値・データは元ソースで確認
3. 引用・参考文献は実在を確認
4. そのまま外部公開しない
```

### 承認フロー例

```
個人利用 → 社内共有（上長確認） → 社外公開（部門長承認）
```

## 社内ルール策定フレームワーク

### 最低限決めるべきこと

1. **利用可能なツール**: 会社として許可するサービス
2. **禁止事項**: 入力してはいけない情報の定義
3. **利用目的**: 許可される利用シーン
4. **承認フロー**: 成果物公開時の承認プロセス
5. **報告義務**: インシデント発生時の報告先

### ルール例

```markdown
# 生成AI利用ガイドライン

## 利用可能ツール
- [ツール名]（企業プラン）

## 禁止事項
- 顧客情報の入力
- 未公開財務情報の入力
- 契約書原文の入力

## 利用目的
- 社内文書の作成補助
- アイデア出し
- 情報整理

## 出力の取り扱い
- 社内利用: 本人責任
- 社外公開: 上長承認必須
```

## インシデント事例と教訓

| 事例 | 内容 | 教訓 |
|-----|-----|-----|
| サムスン | ソースコードをChatGPTに入力 | 機密情報の入力禁止を徹底 |
| 弁護士 | 存在しない判例を引用 | ファクトチェック必須 |
| 画像生成 | 著作権侵害の疑い | 商用利用は慎重に |

## 演習案（ハンズオン用）

1. 自社のリスクシナリオを洗い出し
2. 簡易ガイドラインをドラフト作成
3. ケーススタディ（これはOK? NG?）
